{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "dataset = Planetoid(\"../datasets/Cora\", \"Cora\")\n",
    "data = dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from graph_hscn.layer.sc_layer import SCLayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from graph_hscn.loader.dataset.peptides_structural import PeptidesStructuralDataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = PeptidesStructuralDataset(\"../datasets/peptides_structural\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = data.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  1,  ..., 65, 65, 66],\n        [ 1,  0,  2,  ..., 62, 66, 65]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "2344859"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2344859x9 and 2344859x9)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m sc \u001B[38;5;241m=\u001B[39m SCLayer([\u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m9\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReLU\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m2344859\u001B[39m, \u001B[38;5;241m3\u001B[39m, [\u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m9\u001B[39m])\n\u001B[0;32m----> 2\u001B[0m clusters, mc_loss, o_loss \u001B[38;5;241m=\u001B[39m \u001B[43msc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint64\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mhist(clusters\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/graph_hscn/layer/sc_layer.py:124\u001B[0m, in \u001B[0;36mSCLayer.forward\u001B[0;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"SC-GNN forward pass.\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03mPerforms a forward pass of the spectral clustering GNN module on the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;124;03m      orthogonal loss of the module.\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Propagate node feats\u001B[39;00m\n\u001B[0;32m--> 124\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;66;03m# Cluster assignments (logits)\u001B[39;00m\n\u001B[1;32m    127\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(x)\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/tmp/camille_pyg/tmp0_osnxro.py:18\u001B[0m, in \u001B[0;36mSequential_363866.forward\u001B[0;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_weight):\n\u001B[1;32m     17\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule_0\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule_1(x)\n\u001B[1;32m     20\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule_2(x, edge_index, edge_weight)\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/graph_conv.py:81\u001B[0m, in \u001B[0;36mGraphConv.forward\u001B[0;34m(self, x, edge_index, edge_weight, size)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[1;32m     79\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(edge_index, x\u001B[38;5;241m=\u001B[39mx, edge_weight\u001B[38;5;241m=\u001B[39medge_weight,\n\u001B[1;32m     80\u001B[0m                      size\u001B[38;5;241m=\u001B[39msize)\n\u001B[0;32m---> 81\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlin_rel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     83\u001B[0m x_r \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x_r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Code/school/DSC180B/graph_hscn/.venv/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:136\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    132\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;124;03m        x (Tensor): The features.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (2344859x9 and 2344859x9)"
     ]
    }
   ],
   "source": [
    "sc = SCLayer([9, 9], \"ReLU\", 2344859, 3, [9, 9])\n",
    "clusters, mc_loss, o_loss = sc(data.x.float(), data.edge_index.type(torch.int64), data.edge_weight)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(clusters.argmax(axis=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.0774, grad_fn=<AddBackward0>)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_loss + o_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([  74.,    0.,    0.,    0.,    0.,  333.,    0.,    0.,    0.,\n        2301.]),\n array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "class SparseAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_clusters, num_heads, concat=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_clusters = num_clusters\n",
    "        self.num_heads = num_heads\n",
    "        self.concat = concat\n",
    "\n",
    "        self.weight = nn.Parameter(torch.Tensor(num_heads, in_channels, out_channels))\n",
    "        self.bias = nn.Parameter(torch.Tensor(num_heads, out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "        self.cluster_weight = nn.Parameter(torch.Tensor(num_clusters, num_heads, out_channels))\n",
    "        self.cluster_bias = nn.Parameter(torch.Tensor(num_heads, out_channels))\n",
    "        self.reset_cluster_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def reset_cluster_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.cluster_weight)\n",
    "        nn.init.zeros_(self.cluster_bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        num_nodes = x.size(0)\n",
    "        print(x.shape, self.cluster_weight.shape)\n",
    "        attn_coeffs = torch.einsum(\"ij,hjk->hik\", x, self.cluster_weight) + self.cluster_bias\n",
    "        attn_coeffs = F.softmax(attn_coeffs, dim=1)\n",
    "        x = torch.einsum(\"ij,hjk->hik\", x, attn_coeffs * self.weight) * self.bias\n",
    "        x = F.relu(x)\n",
    "\n",
    "        adj = to_dense_adj(edge_index)[0]\n",
    "\n",
    "        deg = torch.sum(adj, dim=1, keepdim=True)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[torch.isinf(deg_inv_sqrt)] = 0\n",
    "        norm_adj = adj * deg_inv_sqrt * deg_inv_sqrt.t()\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for i in range(self.num_heads):\n",
    "            h = torch.mm(norm_adj, x[i])\n",
    "            output.append(h)\n",
    "\n",
    "        if self.concat:\n",
    "            x = torch.cat(output, dim=-1)\n",
    "        else:\n",
    "            x = torch.stack(output, dim=0)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 4]) torch.Size([3, 3, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript j has size 3 for operand 1 which does not broadcast with previously seen size 4",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m sp \u001B[38;5;241m=\u001B[39m SparseAttention(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43msp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclusters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Code/school/DSC180B/gnn_v2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[44], line 29\u001B[0m, in \u001B[0;36mSparseAttention.forward\u001B[0;34m(self, x, edge_index)\u001B[0m\n\u001B[1;32m     27\u001B[0m num_nodes \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcluster_weight\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 29\u001B[0m attn_coeffs \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mij,hjk->hik\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcluster_weight\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcluster_bias\n\u001B[1;32m     30\u001B[0m attn_coeffs \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(attn_coeffs, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     31\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39meinsum(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mij,hjk->hik\u001B[39m\u001B[38;5;124m\"\u001B[39m, x, attn_coeffs \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "File \u001B[0;32m~/Code/school/DSC180B/gnn_v2/.venv/lib/python3.10/site-packages/torch/functional.py:378\u001B[0m, in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m einsum(equation, \u001B[38;5;241m*\u001B[39m_operands)\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(operands) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_einsum\u001B[38;5;241m.\u001B[39menabled:\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001B[39;00m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;66;03m# or the user has disabled using opt_einsum\u001B[39;00m\n\u001B[0;32m--> 378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mequation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperands\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    380\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m opt_einsum\u001B[38;5;241m.\u001B[39mis_available():\n",
      "\u001B[0;31mRuntimeError\u001B[0m: einsum(): subscript j has size 3 for operand 1 which does not broadcast with previously seen size 4"
     ]
    }
   ],
   "source": [
    "sp = SparseAttention(3, 16, 3, 3)\n",
    "sp(clusters, data.edge_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([2704.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n           4.]),\n array([1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2708, 3])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 10556])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
