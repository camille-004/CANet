{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d2d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .peptides_functional.pyg.peptides_functional import *\n",
    "# from experiments.peptides_structural.pyg.peptides_structural import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2b4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from graph_hscn.loader.dataset.peptides_functional import PeptidesFunctionalDataset\n",
    "from graph_hscn.loader.dataset.peptides_structural import PeptidesStructuralDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab216228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Spectral Clustering GNN layer definition.\"\"\"\n",
    "import os.path as osp\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GraphConv, dense_mincut_pool\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.nn import Sequential\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 mp_units,\n",
    "                 mp_act,\n",
    "                 in_channels, \n",
    "                 n_clusters, \n",
    "                 mlp_units=[],\n",
    "                 mlp_act=\"Identity\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        mp_act = getattr(torch.nn, mp_act)(inplace=True)\n",
    "        mlp_act = getattr(torch.nn, mlp_act)(inplace=True)\n",
    "        \n",
    "        # Message passing layers\n",
    "        mp = [\n",
    "            (GraphConv(in_channels, mp_units[0]), 'x, edge_index, edge_weight -> x'),\n",
    "            mp_act\n",
    "        ]\n",
    "        for i in range(len(mp_units)-1):\n",
    "            mp.append((GraphConv(mp_units[i], mp_units[i+1]), 'x, edge_index, edge_weight -> x'))\n",
    "            mp.append(mp_act)\n",
    "        self.mp = Sequential('x, edge_index, edge_weight', mp)\n",
    "        out_chan = mp_units[-1]\n",
    "        \n",
    "        # MLP layers\n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        for units in mlp_units:\n",
    "            self.mlp.append(Linear(out_chan, units))\n",
    "            out_chan = units\n",
    "            self.mlp.append(mlp_act)\n",
    "        self.mlp.append(Linear(out_chan, n_clusters))\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        \n",
    "        # Propagate node feats\n",
    "        x = self.mp(x, edge_index, edge_weight) \n",
    "        \n",
    "        # Cluster assignments (logits)\n",
    "        s = self.mlp(x) \n",
    "        \n",
    "        # Obtain MinCutPool losses\n",
    "        adj = utils.to_dense_adj(edge_index)\n",
    "        #return x, adj, s\n",
    "        _, _, mc_loss, o_loss = dense_mincut_pool(x, adj, s)\n",
    "        \n",
    "        return torch.softmax(s, dim=-1), mc_loss, o_loss, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11e2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from typing import Literal\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.graphgym.checkpoint import clean_ckpt, save_ckpt\n",
    "from torch_geometric.graphgym.config import cfg\n",
    "from torch_geometric.graphgym.loss import compute_loss\n",
    "from torch_geometric.graphgym.model_builder import GraphGymModule\n",
    "from torch_geometric.graphgym.register import register_train\n",
    "from torch_geometric.graphgym.utils.epoch import is_ckpt_epoch, is_eval_epoch\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15824db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, global_mean_pool, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80141569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset = PeptidesFunctionalDataset(\"../datasets\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train': tensor([    1,     3,     4,  ..., 15531, 15533, 15534]),\n 'val': tensor([    6,    11,    17,  ..., 15496, 15499, 15527]),\n 'test': tensor([    0,     2,     5,  ..., 15521, 15528, 15532])}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_idx_split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15535/15535 [02:23<00:00, 107.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from yacs.config import CfgNode as CN\n",
    "from graph_hscn.config.posenc_config import set_cfg_posenc\n",
    "\n",
    "cfg = CN()\n",
    "set_cfg_posenc(cfg)\n",
    "cfg.posenc_SignNet.model = \"DeepSet\"\n",
    "cfg.posenc_SignNet.post_layers = 1\n",
    "cfg.posenc_SignNet.eigen.max_freqs = 20\n",
    "cfg.posenc_SignNet.enable = True\n",
    "\n",
    "\"\"\"Functions for precomputing positional encoding stats.\"\"\"\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import (  # noqa\n",
    "    get_laplacian,\n",
    "    to_scipy_sparse_matrix,\n",
    "    to_undirected,\n",
    ")\n",
    "from yacs.config import CfgNode\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "Normalization = Literal[\"L1\", \"L2\", \"abs-max\"]\n",
    "\n",
    "def pre_transform_in_memory(\n",
    "    dataset: Data, transform_func: Callable, show_progress: bool = False\n",
    ") -> Data | None:\n",
    "    \"\"\"Apply a transform function to InMemoryDataset in pre_transform stage.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Data\n",
    "        Dataset to pre-transform.\n",
    "    transform_func : Callable\n",
    "        Transform function to apply.\n",
    "    show_progress : bool\n",
    "        Whether to show progress in tqdm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Data | None\n",
    "        Dataset if no transform_func specified, None otherwise.\n",
    "    \"\"\"\n",
    "    if transform_func is None:\n",
    "        return dataset\n",
    "\n",
    "    data_list = [\n",
    "        transform_func(dataset.get(i))\n",
    "        for i in tqdm(\n",
    "            range(len(dataset)),\n",
    "            disable=not show_progress,\n",
    "            mininterval=10,\n",
    "            miniters=len(dataset) // 20,\n",
    "        )\n",
    "    ]\n",
    "    data_list = list(filter(None, data_list))\n",
    "    dataset._indices = None\n",
    "    dataset._data_list = data_list\n",
    "    dataset.data, dataset.slices = dataset.collate(data_list)\n",
    "\n",
    "\n",
    "def compute_posenc_stats(\n",
    "    data: Data, pe_types: list[str], is_undirected: bool, cfg: CfgNode\n",
    "):\n",
    "    \"\"\"Precompute positional encodings for the given graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Data\n",
    "        PyG graph object.\n",
    "    pe_types : list[str]\n",
    "        Positional encoding types to precompute statistics for.\n",
    "    is_undirected : bool\n",
    "        Whether the graph is expected to be undirected.\n",
    "    cfg : CfgNode\n",
    "        Configuration node for experiment.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Data\n",
    "        Extended PyG graph object.\n",
    "    \"\"\"\n",
    "    for t in pe_types:\n",
    "        if t not in [\n",
    "            \"LapPE\",\n",
    "            \"EquivStableLapPE\",\n",
    "            \"SignNet\",\n",
    "        ]:\n",
    "            raise ValueError(\n",
    "                f\"Unexpected PE stats selection {t} in {pe_types}\"\n",
    "            )\n",
    "\n",
    "    if hasattr(data, \"num_nodes\"):\n",
    "        N = data.num_nodes\n",
    "    else:\n",
    "        N = data.x.shape[0]\n",
    "\n",
    "    laplacian_norm_type = cfg.posenc_LapPE.eigen.laplacian_norm.lower()\n",
    "\n",
    "    if laplacian_norm_type == \"none\":\n",
    "        laplacian_norm_type = None\n",
    "\n",
    "    if is_undirected:\n",
    "        undir_edge_index = data.edge_index\n",
    "    else:\n",
    "        undir_edge_index = to_undirected(data.edge_index)\n",
    "\n",
    "    # Eigenvalues and eigenvectors\n",
    "    evals, evects = None, None\n",
    "\n",
    "    if \"LaPE\" in pe_types or \"EquivStableLapPE\" in pe_types:\n",
    "        L = to_scipy_sparse_matrix(\n",
    "            *get_laplacian(\n",
    "                undir_edge_index,\n",
    "                normalization=laplacian_norm_type,\n",
    "                num_nodes=N,\n",
    "            )\n",
    "        )\n",
    "        evals, evects = np.linalg.eigh(L.toarray())\n",
    "\n",
    "        max_freqs, eigvec_norm = None, None\n",
    "\n",
    "        if \"LapPE\" in pe_types:\n",
    "            max_freqs = cfg.posenc_LapPE.eigen.max_freqs\n",
    "            eigvec_norm = cfg.posenc_LapPE.eigen.eigvec_norm\n",
    "        elif \"EquivStableLapPE\" in pe_types:\n",
    "            max_freqs = cfg.posenc_EquivStableLapPE.eigen.max_freqs\n",
    "            eigvec_norm = cfg.posenc_EquivStableLapPE.eigen.eigvec_norm\n",
    "\n",
    "        data.eig_vals, data.eig_vecs = get_lap_decomp_stats(\n",
    "            evals=evals,\n",
    "            evects=evects,\n",
    "            max_freqs=max_freqs,\n",
    "            eigvec_norm=eigvec_norm,\n",
    "        )\n",
    "\n",
    "    if \"SignNet\" in pe_types:\n",
    "        norm_type = cfg.posenc_SignNet.eigen.laplacian_norm.lower()\n",
    "\n",
    "        if norm_type == \"none\":\n",
    "            norm_type = None\n",
    "\n",
    "        L = to_scipy_sparse_matrix(\n",
    "            *get_laplacian(\n",
    "                undir_edge_index, normalization=norm_type, num_nodes=N\n",
    "            )\n",
    "        )\n",
    "        evals_sn, evects_sn = np.linalg.eigh(L.toarray())\n",
    "        data.eigvals_sn, data.eigvecs_sn = get_lap_decomp_stats(\n",
    "            evals=evals_sn,\n",
    "            evects=evects_sn,\n",
    "            max_freqs=cfg.posenc_SignNet.eigen.max_freqs,\n",
    "            eigvec_norm=cfg.posenc_SignNet.eigen.eigvec_norm,\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_lap_decomp_stats(\n",
    "    evals: torch.Tensor,\n",
    "    evects: torch.Tensor,\n",
    "    max_freqs: int,\n",
    "    eigvec_norm: Normalization = \"L2\",\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Compute Laplacian eigen-decomposition-based PE stats of a graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    evals : torch.Tensor\n",
    "        Precomputed eigenvalues.\n",
    "    evects : torch.Tensor\n",
    "        Precomputed eigenvectors.\n",
    "    max_freqs : int\n",
    "        Maximum number of top smallest frequencies/eigenvectors to use.\n",
    "    eigvec_norm : Normalization\n",
    "        Normalization for the eigenvectors of the Laplacian.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[torch.Tensor, torch.Tensor]\n",
    "        Tensor (num_nodes, max_freqs, 1) eigenvalues repeated for each node.\n",
    "        Tensor (num_nodes, max_freqs) of eigenvector values per node.\n",
    "    \"\"\"\n",
    "    N = len(evals)  # Number of nodes, including disconnected nodes\n",
    "\n",
    "    idx = evals.argsort()[:max_freqs]\n",
    "    evals, evects = evals[idx], np.real(evects[:, idx])\n",
    "    evals = torch.from_numpy(np.real(evals)).clamp_min(0)\n",
    "\n",
    "    # Normalize and pad eigenvectors.\n",
    "    evects = torch.from_numpy(evects).float()\n",
    "    evects = eigvec_normalizer(evects, evals, normalization=eigvec_norm)\n",
    "\n",
    "    if N < max_freqs:\n",
    "        eig_vecs = F.pad(evects, (0, max_freqs - N), value=float(\"nan\"))\n",
    "    else:\n",
    "        eig_vecs = evects\n",
    "\n",
    "    # Pad and save eigenvalues.\n",
    "    if N < max_freqs:\n",
    "        eig_vals = F.pad(\n",
    "            evals, (0, max_freqs - N), value=float(\"nan\")\n",
    "        ).unsqueeze(0)\n",
    "    else:\n",
    "        eig_vals = evals.unsqueeze(0)\n",
    "\n",
    "    eig_vals = eig_vals.repeat(N, 1).unsqueeze(2)\n",
    "\n",
    "    return eig_vals, eig_vecs\n",
    "\n",
    "\n",
    "def eigvec_normalizer(\n",
    "    eig_vecs: torch.Tensor,\n",
    "    eig_vals: torch.Tensor,\n",
    "    normalization: Normalization = \"L2\",\n",
    "    eps: float = 1e-12,\n",
    "):\n",
    "    \"\"\"Implement different eigenvector normalizations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eig_vecs : torch.Tensor\n",
    "        Eigenvectors of data.\n",
    "    eig_vals : torch.Tensor\n",
    "        Eigenvalues of data.\n",
    "    normalization : Normalization\n",
    "        Normalization scheme.\n",
    "    eps: float\n",
    "        Epsilon for clamping.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Normalized eigenvectors.\n",
    "    \"\"\"\n",
    "    match normalization:\n",
    "        case \"L1\":\n",
    "            # eigvec / sum(abs(eigvec))\n",
    "            denom = eig_vecs.norm(p=1, dim=0, keepdim=True)\n",
    "        case \"L2\":\n",
    "            # eigvec / sqrt(sum(eigvec^2))\n",
    "            denom = eig_vecs.norm(p=2, dim=0, keepdim=True)\n",
    "        case \"abs-max\":\n",
    "            # eigvec / max(|eigvec|)\n",
    "            denom = torch.max(eig_vecs.abs(), dim=0, keepdim=True).values\n",
    "        case other:\n",
    "            raise ValueError(f\"Unsupported normalization `{normalization}`\")\n",
    "\n",
    "    denom = denom.clamp_min(eps).expand_as(eig_vecs)\n",
    "    eig_vecs = eig_vecs / denom\n",
    "\n",
    "    return eig_vecs\n",
    "\n",
    "\n",
    "pe_enabled_list = []\n",
    "for key, pecfg in cfg.items():\n",
    "    if key.startswith('posenc_') and pecfg.enable:\n",
    "        pe_name = key.split('_', 1)[1]\n",
    "        pe_enabled_list.append(pe_name)\n",
    "        if hasattr(pecfg, 'kernel'):\n",
    "            # Generate kernel times if functional snippet is set.\n",
    "            if pecfg.kernel.times_func:\n",
    "                pecfg.kernel.times = list(eval(pecfg.kernel.times_func))\n",
    "            logging.info(f\"Parsed {pe_name} PE kernel times / steps: \"\n",
    "                         f\"{pecfg.kernel.times}\")\n",
    "if pe_enabled_list:\n",
    "    start = time.perf_counter()\n",
    "    logging.info(f\"Precomputing Positional Encoding statistics: \"\n",
    "                 f\"{pe_enabled_list} for all graphs...\")\n",
    "    # Estimate directedness based on 10 graphs to save time.\n",
    "    is_undirected = all(d.is_undirected() for d in dataset[:10])\n",
    "    logging.info(f\"  ...estimated to be undirected: {is_undirected}\")\n",
    "    pre_transform_in_memory(dataset,\n",
    "                            partial(compute_posenc_stats,\n",
    "                                    pe_types=pe_enabled_list,\n",
    "                                    is_undirected=is_undirected,\n",
    "                                    cfg=cfg),\n",
    "                            show_progress=True\n",
    "                            )\n",
    "    elapsed = time.perf_counter() - start\n",
    "    timestr = time.strftime('%H:%M:%S', time.gmtime(elapsed)) \\\n",
    "              + f'{elapsed:.2f}'[-3:]\n",
    "    logging.info(f\"Done! Took {timestr}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1063/15535 [00:12<03:46, 64.02it/s]"
     ]
    }
   ],
   "source": [
    "enc = SignNetNodeEncoder(cfg, dataset.num_features, 32)\n",
    "new_dataset = []\n",
    "for data in tqdm(dataset):\n",
    "    new_dataset += enc(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b444e9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15535/15535 [00:30<00:00, 512.08it/s]\n",
      "100%|██████████| 15535/15535 [00:35<00:00, 435.86it/s]\n",
      "100%|██████████| 15535/15535 [00:49<00:00, 317.03it/s]\n",
      "100%|██████████| 15535/15535 [00:24<00:00, 627.18it/s]\n",
      "100%|██████████| 15535/15535 [00:24<00:00, 640.76it/s]\n",
      "100%|██████████| 15535/15535 [00:24<00:00, 645.15it/s]\n",
      " 87%|████████▋ | 13490/15535 [00:24<00:04, 469.43it/s]"
     ]
    }
   ],
   "source": [
    "model = Net([16], \"ELU\", dataset.num_features, 5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.train()\n",
    "\n",
    "all_loss = []\n",
    "for epoch in range(1, 11):\n",
    "    for data in tqdm(dataset):\n",
    "        data.edge_index, data.edge_weight = gcn_norm(  \n",
    "                 data.edge_index, data.edge_weight, data.num_nodes,\n",
    "                 add_self_loops=True)\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        _, mc_loss, o_loss, adj = model(data.x.float(), data.edge_index, data.edge_weight)\n",
    "        loss = mc_loss + o_loss\n",
    "        all_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b073bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_all_lst = []\n",
    "for data in tqdm(dataset):\n",
    "    data.edge_index, data.edge_weight = gcn_norm(  \n",
    "             data.edge_index, data.edge_weight, data.num_nodes,\n",
    "             add_self_loops=True)\n",
    "    data = data.to(device)\n",
    "    clust, _, _, adj = model(data.x.float(), data.edge_index, data.edge_weight)\n",
    "    colors = clust.max(1)[1].cpu().numpy()\n",
    "    color_all_lst.append(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "627552e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hg_dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['peptides_func_hetero.npy']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['peptides_func_hetero.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        # dataset = PeptidesFunctionalDataset(\"/home/zluo/\")\n",
    "        \n",
    "        color_all_lst = np.load(\"color_all_lst.npy\", allow_pickle=True)\n",
    "        h_data_lst = []\n",
    "        \n",
    "        if self.pre_filter is not None:\n",
    "            h_data_lst = [data for data in h_data_lst if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            h_data_lst = [self.pre_transform(data) for data in h_data_lst]\n",
    "\n",
    "        for idx in tqdm(range(len(dataset))):\n",
    "            data = dataset[idx].to(device)\n",
    "            clust_node = [[] for idx in range(5)]\n",
    "            colors = color_all_lst[idx]\n",
    "            unique_colors = np.unique(colors)\n",
    "            clus_map = {unique_colors[idx]: idx for idx in range(len(unique_colors))}\n",
    "            colors = [clus_map[val] for val in colors]\n",
    "            for idx in range(data.num_nodes):\n",
    "                clust_num = colors[idx] - 1\n",
    "                clust_node[clust_num].append(data.x[idx].tolist())\n",
    "\n",
    "            clust_node = [lst for lst in clust_node if len(lst) != 0]\n",
    "            clust_mean = [np.mean(clust_lst, axis=0) for clust_lst in clust_node]\n",
    "            clust_mean = np.array(clust_mean)\n",
    "\n",
    "            num_clust = len(clust_mean)\n",
    "            h_data = HeteroData()\n",
    "            h_data['local'].x = data.x.float()\n",
    "            h_data['local'].y = data.y\n",
    "            h_data['virtual'].x = torch.FloatTensor(clust_mean)\n",
    "            h_data['local', 'to', 'local'].edge_index = data.edge_index\n",
    "            col = np.concatenate([[idx] * (num_clust - idx) for idx in range(num_clust)])\n",
    "            row = np.concatenate([[idx for idx in range(num_clust - index)] for index in range(num_clust)])\n",
    "            h_data['virtual', 'to', 'virtual'].edge_index = torch.LongTensor([list(col), list(row)])\n",
    "\n",
    "            edge_lst = []\n",
    "            for idx in range(len(colors)):\n",
    "                clust_num = colors[idx]\n",
    "                edge_lst.append([idx, clust_num])\n",
    "\n",
    "            h_data['local', 'to', 'virtual'].edge_index = torch.LongTensor(edge_lst).T\n",
    "\n",
    "            h_data_lst.append(h_data)\n",
    "\n",
    "        data, slices = self.collate(h_data_lst)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1aa96329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_dataset = hg_dataset(\"../datasets/peptides_func_hetero\")\n",
    "h_dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07779296",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d0f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                                                                                 | 89/15535 [02:22<7:56:22,  1.85s/it]"
     ]
    }
   ],
   "source": [
    "for data in tqdm(dataset):\n",
    "    data.edge_index, data.edge_weight = gcn_norm(  \n",
    "                data.edge_index, data.edge_weight, data.num_nodes,\n",
    "                add_self_loops=False)\n",
    "    data = data.to(device)\n",
    "\n",
    "    colors = [0]\n",
    "    num_clust = 1\n",
    "    while num_clust < 5:\n",
    "        colors, clust, x = run()\n",
    "        num_clust = len(np.unique(colors))\n",
    "        #print(num_clust)\n",
    "\n",
    "    G = to_networkx(data, node_attrs=[\"x\"])\n",
    "    G = G.to_undirected()\n",
    "\n",
    "\n",
    "    nodelist = G.nodes()\n",
    "    clust_node = [[] for idx in range(5)]\n",
    "    for idx in range(len(nodelist)):\n",
    "        clust_num = colors[idx] - 1\n",
    "        clust_node[clust_num].append(nodelist[idx]['x'])\n",
    "\n",
    "    clust_node = [lst for lst in clust_node if len(lst) != 0]\n",
    "\n",
    "    clust_mean = [np.mean(clust_lst, axis=0) for clust_lst in clust_node]\n",
    "    clust_mean = np.array(clust_mean)\n",
    "\n",
    "    h_data = HeteroData()\n",
    "    h_data['local'].x = data.x.float()\n",
    "    h_data['local'].y = data.y\n",
    "    h_data['virtual'].x = torch.FloatTensor(clust_mean)\n",
    "    h_data['local', 'to', 'local'].edge_index = data.edge_index\n",
    "    col = np.concatenate([[idx] * (num_clust - idx) for idx in range(num_clust)])\n",
    "    row = np.concatenate([[idx for idx in range(num_clust - index)] for index in range(num_clust)])\n",
    "    h_data['virtual', 'to', 'virtual'].edge_index = torch.LongTensor([list(col), list(row)])\n",
    "\n",
    "    edge_lst = []\n",
    "    for idx in range(len(colors)):\n",
    "        clust_num = colors[idx]\n",
    "        edge_lst.append([idx, clust_num])\n",
    "\n",
    "    h_data['local', 'to', 'virtual'].edge_index = torch.LongTensor(edge_lst).T\n",
    "\n",
    "    h_data_lst.append(h_data)    \n",
    "    #print(\"RUN: \" + str(len(h_data_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "225c9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(nn.Module):\n",
    "    def __init__(self, lv_conv, ll_conv, vv_conv, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                (\"local\", \"to\", \"virtual\"): lv_conv((-1, -1), hidden_channels, add_self_loops=False, cached=False),\n",
    "                (\"local\", \"to\", \"local\"): ll_conv(-1, hidden_channels, add_self_loops=False, cached=False),\n",
    "                (\"virtual\", \"to\", \"virtual\"): vv_conv(-1, hidden_channels, add_self_loops=False, cached=False),\n",
    "            }, aggr=\"sum\")\n",
    "            self.convs.append(conv)\n",
    "        \n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, batch):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        \n",
    "        x = global_mean_pool(x_dict[\"local\"], batch)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38cd5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95d66b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, target):\n",
    "    loss = torch.square(output - target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12713ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = HeteroGNN(GATConv, GCNConv, GCNConv, 32, 11, 3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "745fc26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15535/15535 [01:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99976401 0.99930188 0.99046993 0.99911508 1.00095701 0.9963645\n",
      " 0.99832419 0.99449364 0.99664531 0.99440601 0.99661492]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15535/15535 [00:59<00:00, 262.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98978915 0.98806335 0.93322838 0.99114505 0.99336086 0.96013113\n",
      " 0.9901561  0.96133322 0.96821076 0.97264736 0.95505515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15535/15535 [00:59<00:00, 259.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95802834 0.95903133 0.84499626 0.96558172 0.96958096 0.89081626\n",
      " 0.9496801  0.89185419 0.9028089  0.96494372 0.88447096]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                      | 1109/15535 [00:04<00:55, 259.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_555913/127108012.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mx_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0medge_index_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'local'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mall_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_555913/3484198009.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x_dict, edge_index_dict, batch)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_index_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mconv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m             \u001B[0mx_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_index_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m             \u001B[0mx_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/hetero_conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x_dict, edge_index_dict, *args_dict, **kwargs_dict)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0msrc\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mdst\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m                 \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m                 out = conv((x_dict[src], x_dict[dst]), edge_index, *args,\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m    173\u001B[0m                 \u001B[0mcache\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cached_edge_index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mcache\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001B[0m\u001B[1;32m    176\u001B[0m                         \u001B[0medge_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnode_dim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m                         self.improved, self.add_self_loops, self.flow)\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001B[0m in \u001B[0;36mgcn_norm\u001B[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0mrow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0medge_index\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_index\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         \u001B[0midx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcol\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mflow\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"source_to_target\"\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0mdeg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscatter_add\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0medge_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_nodes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m         \u001B[0mdeg_inv_sqrt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdeg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpow_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0mdeg_inv_sqrt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmasked_fill_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdeg_inv_sqrt\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'inf'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch_scatter/scatter.py\u001B[0m in \u001B[0;36mscatter_add\u001B[0;34m(src, index, dim, out, dim_size)\u001B[0m\n\u001B[1;32m     27\u001B[0m                 \u001B[0mout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m                 dim_size: Optional[int] = None) -> torch.Tensor:\n\u001B[0;32m---> 29\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mscatter_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch_scatter/scatter.py\u001B[0m in \u001B[0;36mscatter_sum\u001B[0;34m(src, index, dim, out, dim_size)\u001B[0m\n\u001B[1;32m     19\u001B[0m             \u001B[0msize\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscatter_add_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscatter_add_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    model.train()\n",
    "    all_loss = []\n",
    "    for data in tqdm(h_dataset):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x_dict, data.edge_index_dict, None)\n",
    "        loss = mse(output, data['local'].y)\n",
    "        all_loss.append(loss.view(-1).tolist())\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "    print(np.mean(all_loss, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81191d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PeptidesFunctionalDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mPeptidesFunctionalDataset\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'PeptidesFunctionalDataset' is not defined"
     ]
    }
   ],
   "source": [
    "PeptidesFunctionalDataset(\"../../datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0193f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3878, -0.3690, -0.5128, -0.4187, -0.3985, -0.5848, -0.1651, -0.5372,\n",
       "         -0.4686, -0.1788, -0.0827]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['local'].y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
